{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3769,"status":"ok","timestamp":1662108535694,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"e_6Q5lnJ5qH_","outputId":"ea2425cb-fdef-4a94-cc81-fb74a2d3b4ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting early-stopping\n","  Downloading early_stopping-0.1.3-py3-none-any.whl (3.4 kB)\n","Installing collected packages: early-stopping\n","Successfully installed early-stopping-0.1.3\n"]}],"source":["!pip install early-stopping\n","!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73xKc9X5D2YQ"},"outputs":[],"source":["import gc\n","import os\n","import shutil\n","import time\n","import zipfile\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from early_stopping import EarlyStopping\n","from google.colab import drive\n","from PIL import Image\n","from sklearn.metrics import roc_auc_score\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.models import ResNeXt50_32X4D_Weights, resnext50_32x4d\n","from tqdm import tqdm as tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LFaND95MEk6w"},"outputs":[],"source":["#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nkf7BoR3Duq3"},"outputs":[],"source":["with zipfile.ZipFile('/content/drive/MyDrive/UCCD3074/Asm2/cassava-leaf-disease-classification.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1662108574906,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"4VcbhrWV_4-R","outputId":"9491a18c-dfdc-463c-ba56-cc62ae62c960"},"outputs":[{"output_type":"stream","name":"stdout","text":["21397\n","14978\n","3209\n","3210\n"]}],"source":["############################\n","#Coded by Leong Wai Yin\n","############################\n","df = pd.read_csv('/content/cassava-leaf-disease-classification/train.csv')\n","\n","#train, val, test split (70:15:15)\n","df_train = df.sample(frac=0.7, random_state=3074)\n","val_test = df.loc[~df.index.isin(df_train.index)]\n","df_test = val_test.sample(frac=0.5, random_state=3074)\n","df_valid = val_test.loc[~val_test.index.isin(df_test.index)]\n","print(len(df))\n","print(len(df_train))\n","print(len(df_valid))\n","print(len(df_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVXk1SSu3OLl"},"outputs":[],"source":["############################\n","#Coded by Leong Wai Yin\n","############################\n","def get_transform(mode=0):\n","\n","  train_transform = [\n","      transforms.Compose([    #no augmentation\n","        transforms.Resize(512),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","      ]),\n","      transforms.Compose([    #slight augmentation with cropping\n","        transforms.Resize(512),\n","        transforms.RandomCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","      ]),\n","      transforms.Compose([    #heavy augmentation\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomRotation(degrees=(0,180)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","      ])\n","  ]\n","\n","  val_transform = [\n","      transforms.Compose([\n","        transforms.Resize(512),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","      ]),\n","      transforms.Compose([\n","        transforms.Resize(512),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","      ]),\n","      transforms.Compose([\n","        transforms.Resize(512),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","      ])\n","  ]  \n","\n","  return train_transform[mode], val_transform[mode]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygb35NV_9_rw"},"outputs":[],"source":["def get_trainloader(batch_size=32, train_transform=None):\n","\n","  trainset = CasavaDataset(df_train, '/content/cassava-leaf-disease-classification/train_images', transform=train_transform)\n","  trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","  return trainloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bk1iHuN9-qWY"},"outputs":[],"source":["def get_validloader(batch_size=32, val_transform=None):\n","\n","  validset = CasavaDataset(df_valid, '/content/cassava-leaf-disease-classification/train_images', transform=val_transform)\n","  validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","  return validloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50MZFwYn-oi3"},"outputs":[],"source":["def get_testloader(batch_size=32, val_transform=None):\n","\n","  testset = CasavaDataset(df_test, '/content/cassava-leaf-disease-classification/train_images', transform=val_transform)\n","  testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","  return testloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrAUFbCaJnxE"},"outputs":[],"source":["############################\n","#Adapted from Lab6B\n","############################\n","class CasavaDataset(Dataset):\n","\n","    def __init__(self, csv, root, transform=None):\n","        self.csv = csv    #store dataset partition csv\n","        self.root = root    #image dataset directory\n","        self.transform = transform    #preprocessing and augmentation method\n","        self.classes = ['CBB', 'CBSD', 'CGM', 'CMD', 'H']   #list of classes\n","\n","    def __len__(self):\n","        return self.csv.shape[0]\n","\n","    def __getitem__(self, idx):\n","        \n","        #get image by index\n","        row=self.csv.iloc[idx]\n","        img = os.path.join(self.root, row.image_id)\n","        image = Image.open(img)\n","        \n","        #transformation\n","        if self.transform is not None:\n","          image = self.transform(image)\n","        \n","        #get image label\n","        label = row.label\n","        \n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLFA85DzrMgG"},"outputs":[],"source":["############################\n","#Adapted from lab6A\n","############################\n","def build_network(weights=None, model):\n","  if model == 'resnext50':\n","    net = resnext50_32x4d(weights=weights)\n","    in_c = net.fc.in_features    #get fc input shape\n","    net.fc = nn.Linear(in_c, 5)   #match model output with number of labels\n","\n","  if model == 'efficientnetb0':\n","    net = timm.create_model('tf_efficientnet_b0_ns', pretrained=True)\n","    in_c = net.classifier.in_features\n","    net.classifier = nn.Linear(in_c, 5)\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUBvnSNqlNIY"},"outputs":[],"source":["############################\n","#Coded by Leong Wai Yin\n","############################\n","loss_iter = 1\n","\n","def train(net, kernel_type, trainloader, validloader, optimizer, scheduler, num_epochs, finetune):\n","    val_loss_best = 1000\n","    history = []\n","    model_file = f'{kernel_type}_{num_epochs}ep_best.pth'\n","\n","    early_stopping = EarlyStopping(depth=5, ignore=10, method='consistency')    #early stopping to prevent overfitting\n","\n","    loss_iterations = int(np.ceil(len(trainloader)/loss_iter))\n","    \n","    #use gpu if available\n","    if torch.cuda.is_available(): \n","        net = net.cuda()\n","    \n","    #train mode\n","    net.train()  \n","    \n","    #iterate training for epochs\n","    for e in range(num_epochs):    \n","        print(time.ctime(), 'Epoch:', e+1)\n","\n","        running_loss = 0.0\n","        running_count = 0.0\n","\n","        bar = tqdm(trainloader)\n","\n","        for (inputs, labels) in bar:\n","            \n","            #clear gradient\n","            optimizer.zero_grad()\n","\n","            #use cuda if available\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            #forward propagation\n","            outs = net(inputs)\n","\n","            #cross entropy loss calculation\n","            loss = F.cross_entropy(outs, labels)\n","\n","            #backprop\n","            loss.backward()\n","\n","            #update weights\n","            optimizer.step()\n","\n","            #accumulate loss\n","            running_loss += loss.item()\n","            running_count += 1\n","\n","        train_loss = running_loss / running_count\n","        running_loss = 0. \n","        running_count = 0.\n","        #calculate train loss per epoch\n","        bar.set_description('loss: %.5f' % (train_loss))   \n","        \n","        #validation epoch\n","        val_loss, acc = validation(net, validloader)    \n","        \n","        #train val epoch summary\n","        if not finetune:    \n","          content = time.ctime() + ' ' + f'Epoch {e}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}'\n","          print(content)\n","\n","          #save model if epoch outperform best val loss\n","          if val_loss < val_loss_best:    \n","              print('val_loss_best ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_best, val_loss))\n","              torch.save(net.state_dict(), model_file)\n","              val_loss_best = val_loss\n","\n","        history.append([e+1,train_loss, val_loss])\n","\n","        #update lr value\n","        scheduler.step(val_loss)   \n","        \n","         #stop training if no more improvement\n","        if early_stopping.check(val_loss):   \n","            print(\"Early stopping\")\n","            break\n","\n","    #save model after final epoch\n","    if not finetune:      \n","      torch.save(net.state_dict(), f'{kernel_type}_{num_epochs}ep_model.pth')\n","    \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukX_1zO60Iz5"},"outputs":[],"source":["####################\n","#Coded by Leong Wai Yin\n","####################\n","def validation(model, validloader):\n","    model.eval()     #evaluation mode\n","    LOGITS = []     #append prediction proba per batch\n","    TARGETS = []    #append actual image label per batch\n","    \n","    running_corrects = 0\n","    running_count = 0\n","\n","    #validate by batch\n","    for (inputs, targets) in tqdm(validloader):\n","        \n","        #use gpu if available\n","        if torch.cuda.is_available():\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","        \n","        #clear gradient\n","        with torch.no_grad():\n","            #forward prop\n","            outputs = model(inputs)\n","            LOGITS.append(outputs.detach().cpu())\n","            TARGETS.append(targets.detach().cpu())\n","            #get argmax label\n","            _, predicted = torch.max(outputs, 1)\n","            #acc calculation\n","            running_corrects += (predicted.view(-1) == targets).sum().double()\n","            running_count += len(inputs)\n","\n","    #val loss calculation\n","    val_loss = F.cross_entropy(torch.cat(LOGITS), torch.cat(TARGETS)).numpy()\n","\n","    acc = 100*running_corrects/running_count\n","\n","    return val_loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt-IaEe75KxB"},"outputs":[],"source":["####################\n","#Coded by Leong Wai Yin\n","####################\n","def run(params, finetune=False):\n","  init_lr = params['lr']            #initial lr\n","  batch_size = params['batch']      #batch size\n","  epochs = params['epochs']         #total epoch\n","  factor = params['factor']         #lr decay factor\n","  patience = params['patience']     #how long to wait before reduce lr\n","  eps = params['eps']               #minimum lr\n","  pretrained_weight = 'IMAGENET1K_V2'\n","  model = params['model']\n","  train_transform, val_transform = get_transform(mode=params['transform'])\n","\n","  net = build_network(pretrained_weight, model)\n","\n","  optimizer = optim.Adam(net.parameters(), lr=init_lr)\n","\n","  scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, eps=eps)  #scheduler to reduce lr based on metric changes\n","\n","  history = train(net, model, get_trainloader(batch_size, train_transform), get_validloader(batch_size, val_transform), optimizer, scheduler, num_epochs=epochs, finetune=finetune)\n","\n","  #dump model and clear gpu memory\n","  net = None\n","  gc.collect()\n","  torch.cuda.empty_cache()\n","\n","  return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srkFFlNTKM67"},"outputs":[],"source":["params = {          #best hyperparameters after finetuning\n","    \"lr\": 1e-4,\n","    \"batch\": 16,\n","    \"epochs\": 20,\n","    \"factor\": 0.2,\n","    \"patience\": 5,\n","    \"eps\": 1e-6,\n","    \"transform\": 1\n","    \"model\": \"resnext50\"\n","}\n","run(params)"]},{"cell_type":"code","source":["params = {          #best hyperparameters after finetuning\n","    \"lr\": 1e-5,\n","    \"batch\": 16,\n","    \"epochs\": 20,\n","    \"factor\": 0.1,\n","    \"patience\": 3,\n","    \"eps\": 1e-7,\n","    \"transform\": 2\n","    \"model\": \"efficientnetb0\"\n","}\n","run(params)"],"metadata":{"id":"-rPh-A_ps8RZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXRY3bybhFL9"},"outputs":[],"source":["def Sort(sub_li):   #sort training history to find best epoch\n","    sub_li.sort(key = lambda x: x[2])\n","    return sub_li"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ngc5hsFKD75m"},"outputs":[],"source":["####################\n","#Coded by Leong Wai Yin\n","####################\n","def fine_tune(model):    #random search finetuning\n","  epoch = 5\n","  model_iteration = 30    #no of hyperparameter combinations\n","  log = []      #to store metric for each model instance\n","\n","  #range of hyperparameter values to fine tune\n","  lr_range = 10**np.random.uniform(np.log10(0.00001), np.log10(0.1), size = model_iteration)    #1e-5 to 1e-1\n","  batch_range = 2**np.random.randint(4, 6, size = model_iteration)                              #16, 32, 64\n","  factor_range = 10**np.random.uniform(np.log10 (0.01), np.log10(0.9), size = model_iteration)  #0.01 to 0.9\n","  patience_range = np.random.randint(1, 5, size = model_iteration)                              #1 to 5\n","  eps_range = 10**np.random.uniform(np.log10(1e-10), np.log10(1e-3), size = model_iteration)    #1e-10 to 1e-3\n","  transform_range = np.random.randint(0, 2, size = model_iteration)                             #no aug, light aug, heavy aug\n","\n","  for i in range(model_iteration):      #repeat training for each hyperparameter combination\n","    params = {\n","      \"lr\": lr_range[i].item(),\n","      \"batch\": batch_range[i].item(),\n","      \"epochs\": epoch,\n","      \"factor\": factor_range[i].item(),\n","      \"patience\": patience_range[i].item(),\n","      \"eps\": eps_range[i].item(),\n","      \"transform\": transform_range[i].item(),\n","      \"model\": model\n","    }\n","    #get train val loss\n","    stat = run(params)    \n","    #only keep best epoch metric and append to main log\n","    log.append([Sort(stat)[0].append(params)])\n","\n","  print(Sort(log))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpDk-D5CibOn"},"outputs":[],"source":["fine_tune(\"resnext50\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1snH_fXHB9vN"},"outputs":[],"source":["#copy saved model weights to drive\n","path = \"/content\"\n","dir_list = os.listdir(path)\n","files = [os.path.join(path, file) for file in dir_list if (file.startswith('resnext') or file.startswith('log'))]\n","for i in files:\n","  shutil.copy(os.path.join('/content/', i),\"/content/drive/MyDrive/casava/resnext50\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"mount_file_id":"1ndEziEK30GTBghqohXImL4WhkqV3Gv8K","authorship_tag":"ABX9TyM3ql4+QSfz4S7+uJiqGrfN"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}