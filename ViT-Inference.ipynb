{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19627,"status":"ok","timestamp":1662263162530,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"NOtnP77-heVp","outputId":"c70d5f89-1c18-4581-8fdf-9c255751a1e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662267664162,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"HqYi-aW6hkJ2","outputId":"064d3555-94f3-4a3f-e894-e68fd99c09fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}],"source":["cd /content/drive/MyDrive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100286,"status":"ok","timestamp":1662263309748,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"dqYEQJMXhkYu","outputId":"7585fe18-0b98-48f1-f0e3-25663c64c427"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  6034  100  6034    0     0  18915      0 --:--:-- --:--:-- --:--:-- 18915\n","Updating... This may take around 2 minutes.\n","Updating TPU runtime to pytorch-1.7 ...\n","Found existing installation: torch 1.12.1+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cloud-tpu-client\n","  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n","Collecting google-api-python-client==1.8.0\n","  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 3.0 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.31.6)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.35.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2022.2.1)\n","Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.56.4)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.9)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n","Uninstalling torch-1.12.1+cu113:\n","Installing collected packages: google-api-python-client, cloud-tpu-client\n","  Attempting uninstall: google-api-python-client\n","    Found existing installation: google-api-python-client 1.12.11\n","    Uninstalling google-api-python-client-1.12.11:\n","      Successfully uninstalled google-api-python-client-1.12.11\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","earthengine-api 0.1.321 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n","Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n","Done updating TPU runtime\n","  Successfully uninstalled torch-1.12.1+cu113\n","Found existing installation: torchvision 0.13.1+cu113\n","Uninstalling torchvision-0.13.1+cu113:\n","  Successfully uninstalled torchvision-0.13.1+cu113\n","Copying gs://tpu-pytorch/wheels/torch-1.7-cp37-cp37m-linux_x86_64.whl...\n","\\ [1 files][114.2 MiB/114.2 MiB]                                                \n","Operation completed over 1 objects/114.2 MiB.                                    \n","Copying gs://tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl...\n","\\ [1 files][127.4 MiB/127.4 MiB]                                                \n","Operation completed over 1 objects/127.4 MiB.                                    \n","Copying gs://tpu-pytorch/wheels/torchvision-1.7-cp37-cp37m-linux_x86_64.whl...\n","/ [1 files][  3.1 MiB/  3.1 MiB]                                                \n","Operation completed over 1 objects/3.1 MiB.                                      \n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./torch-1.7-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (1.21.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (0.16.0)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7) (4.1.1)\n","Installing collected packages: dataclasses, torch\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.9 requires torchvision>=0.8.2, which is not installed.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0a0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0a0 which is incompatible.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.7.0a0 which is incompatible.\u001b[0m\n","Successfully installed dataclasses-0.6 torch-1.7.0a0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./torch_xla-1.7-cp37-cp37m-linux_x86_64.whl\n","Installing collected packages: torch-xla\n","Successfully installed torch-xla-1.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./torchvision-1.7-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==1.7) (7.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==1.7) (1.7.0a0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==1.7) (1.21.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==1.7) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==1.7) (0.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==1.7) (4.1.1)\n","Installing collected packages: torchvision\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.7.0a0 which is incompatible.\u001b[0m\n","Successfully installed torchvision-0.9.0a0+75e4a7d\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  libomp5\n","0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 234 kB of archives.\n","After this operation, 774 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n","Fetched 234 kB in 0s (625 kB/s)\n","Selecting previously unselected package libomp5:amd64.\n","(Reading database ... 155685 files and directories currently installed.)\n","Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n","Unpacking libomp5:amd64 (5.0.1-1) ...\n","Setting up libomp5:amd64 (5.0.1-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n","\u001b[K     |████████████████████████████████| 509 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.7.0a0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.9.0a0+75e4a7d)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Installing collected packages: timm\n","Successfully installed timm-0.6.7\n"]}],"source":["############################\n","#Reference: <https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook>\n","############################\n","\n","#install TPU dependencies\n","!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py #transfer data to the notebook\n","!python pytorch-xla-env-setup.py --version 1.7 #get and setup torch_xla version\n","!pip install timm "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6028,"status":"ok","timestamp":1662267675273,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"lh2FjxwR6-SQ","outputId":"0f881a24-eeaa-4401-8cad-8c475765a6e3"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:TPU has started up successfully with version pytorch-1.7\n"]},{"output_type":"stream","name":"stdout","text":["torchversion: 1.7.0a0+7e71a98\n"]}],"source":["#import library\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","plt.style.use(\"ggplot\")\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","\n","import albumentations\n","\n","import torch_xla #to connect notebook to use Cloud TPU device\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","import torch_xla.distributed.parallel_loader as pl\n","\n","import timm #to collect newest computer vision model\n","\n","import gc #garbage collector\n","import os #operating system\n","import time\n","import random #generate random number\n","from datetime import datetime\n","\n","from PIL import Image\n","from tqdm.notebook import tqdm #to create progress bar\n","from sklearn import model_selection, metrics\n","\n","# For parallelization in TPUs\n","os.environ[\"XLA_USE_BF16\"] = \"1\"\n","os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"\n","\n","print(\"torchversion:\",torch.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QUOVEMzqSEzq","executionInfo":{"status":"ok","timestamp":1662267675275,"user_tz":-480,"elapsed":10,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"outputs":[],"source":["############################\n","#Coded by Ng Jiun Shen\n","############################\n","\n","# model specific global variables\n","Set = {\n","    'seed': 3074,\n","    'model_arch': 'vit_base_patch16_224',\n","    'img_size': 224,\n","    'epochs': 10,\n","    'train_bs': 16,\n","    'valid_bs': 16,\n","    'lr': 2e-05,\n","}"]},{"cell_type":"code","source":["import zipfile\n","with zipfile.ZipFile('/content/drive/MyDrive/UCCD3074/Asm2/cassava-leaf-disease-classification.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content')"],"metadata":{"id":"27T2uqW8n6Bt","executionInfo":{"status":"ok","timestamp":1662263536757,"user_tz":-480,"elapsed":37170,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1662267675275,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"TkRGO8rKxEiJ","outputId":"02fe7b8d-f02b-42f1-a007-85b9fe16b5f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["top 5 records\n","          image_id  label\n","0  1000015157.jpg      0\n","1  1000201771.jpg      3\n","2   100042118.jpg      1\n","3  1000723321.jpg      1\n","4  1000812911.jpg      3\n","\n","last 5 records\n","             image_id  label\n","21392  999068805.jpg      3\n","21393  999329392.jpg      3\n","21394  999474432.jpg      1\n","21395  999616605.jpg      4\n","21396  999998473.jpg      4\n"]}],"source":["############################\n","#Coded by Ng Jiun Shen\n","############################\n","\n","#read file\n","df = pd.read_csv('/content/cassava-leaf-disease-classification/train.csv')\n","\n","#check success loaded\n","print(\"top 5 records\\n\",df.head()) \n","print(\"\\nlast 5 records\\n\",df.tail()) "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662267675275,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"},"user_tz":-480},"id":"wwETGANchki-","outputId":"8f9d0d0b-72cf-4cd1-cc52-e9f4924df108"},"outputs":[{"output_type":"stream","name":"stdout","text":["dataset's length is 21397\n","trainset's length is 14978\n","validset's length is 3209\n","testset's length is 3210\n"]}],"source":["############################\n","#Coded by Leong Wai Yin\n","############################\n","\n","#Split into train,valid,test set\n","df_train = df.sample(frac=0.7, random_state=Set['seed'])\n","val_test = df.loc[~df.index.isin(df_train.index)]\n","df_test = val_test.sample(frac=0.5, random_state=Set['seed'])\n","df_valid = val_test.loc[~val_test.index.isin(df_test.index)]\n","print(\"dataset's length is\",len(df))\n","print(\"trainset's length is\",len(df_train))\n","print(\"validset's length is\",len(df_valid))\n","print(\"testset's length is\",len(df_test))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZAYTgcrghksu","executionInfo":{"status":"ok","timestamp":1662267675809,"user_tz":-480,"elapsed":3,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"outputs":[],"source":["############################\n","#Reference: <https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook>\n","############################\n","\n","class CassavaDataset(torch.utils.data.Dataset): #class for dataset\n","    def __init__(self, df, data_path=\"/content/cassava-leaf-disease-classification\", mode=\"train\", transforms=None):\n","        super().__init__()\n","        self.df_data = df.values\n","        self.data_path = data_path\n","        self.transforms = transforms\n","        self.mode = mode\n","        self.data_dir = \"train_images\" if mode == \"train\" else \"test_images\"\n","\n","    def __len__(self):\n","        return len(self.df_data)\n","\n","    def __getitem__(self, index):\n","        img_name, label = self.df_data[index] #assign index to each image\n","        img_path = os.path.join(self.data_path, self.data_dir, img_name)\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        if self.transforms is not None:\n","            image = self.transforms(img)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vsIQKHsR0lnj","executionInfo":{"status":"ok","timestamp":1662267677708,"user_tz":-480,"elapsed":3,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"outputs":[],"source":["############################\n","#Adapted from <https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook>\n","############################\n","\n","# create image augmentations\n","transforms_valid = transforms.Compose( #no augmentation in valid set\n","    [\n","        transforms.Resize((Set['img_size'], Set['img_size'])),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    ]\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zLHmXy8nhk1A","executionInfo":{"status":"ok","timestamp":1662267678843,"user_tz":-480,"elapsed":3,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"outputs":[],"source":["############################\n","#Reference: <https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook>\n","############################\n","\n","class ViTBase16(nn.Module): #class for VIT module\n","    def __init__(self, n_classes, pretrained=False):\n","\n","        super(ViTBase16, self).__init__()\n","\n","        self.model = timm.create_model(Set['model_arch'], pretrained=False)\n","        if pretrained:\n","            self.model.load_state_dict(torch.load(\"../Assignment2/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"))\n","\n","        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x\n","\n","    def inference(self, test_loader, device):\n","        logits = []\n","        self.model.eval()\n","        for data, target in test_loader:\n","            # move tensors to GPU if CUDA is available\n","            if device.type == \"cuda\":\n","                data, target = data.cuda(), target.cuda()\n","            elif device.type == \"xla\":\n","                data = data.to(device, dtype=torch.float32)\n","                target = target.to(device, dtype=torch.int64)\n","\n","            with torch.no_grad():\n","                # forward pass: compute predicted outputs by passing inputs to the model\n","                output = self.model(data)\n","                # calculate the batch loss\n","                logits.append(output.detach().cpu())\n","        probs = torch.sigmoid(torch.cat(logits)).numpy().squeeze()\n","               \n","        return probs\n","          "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kANh2IGlhlFo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662267746959,"user_tz":-480,"elapsed":65859,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}},"outputId":"f3feadf0-3f67-4a7e-d862-464f834710bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.24364243, 0.15507847, 0.15002882, 0.6959583 , 0.9890131 ],\n","       [0.02843603, 0.02479816, 0.31237   , 0.9905874 , 0.32167307],\n","       [0.6959583 , 0.05749328, 0.19559409, 0.23231015, 0.9046505 ],\n","       ...,\n","       [0.03676946, 0.01542455, 0.15713686, 0.9879462 , 0.7879312 ],\n","       [0.13386749, 0.20307462, 0.02887091, 0.99444515, 0.12678517],\n","       [0.6522414 , 0.8056322 , 0.35577488, 0.28378138, 0.64332926]],\n","      dtype=float32)"]},"metadata":{},"execution_count":9}],"source":["############################\n","#Reference: <https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline/notebook>\n","############################\n","valid_dataset = CassavaDataset(df_test, transforms=transforms_valid)\n","\n","valid_sampler = torch.utils.data.distributed.DistributedSampler(\n","        valid_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=False,\n","    )\n","\n","valid_loader = torch.utils.data.DataLoader(\n","        dataset=valid_dataset,\n","        batch_size=Set['valid_bs'],\n","        sampler=valid_sampler,\n","        num_workers=8,\n","    )\n","\n","model = ViTBase16(n_classes=5)\n","device = xm.xla_device()\n","model.to(device)\n","state_dict = torch.load('/content/drive/MyDrive/model_5e_20220903-1457.pth')\n","model.load_state_dict(state_dict, strict=True)\n","para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n","probs = model.inference(para_valid_loader.per_device_loader(device), device)\n","probs"]},{"cell_type":"code","source":["pd.DataFrame(probs).to_csv('vit_probs.csv', index=False)"],"metadata":{"id":"TkfNhq2XtbDK","executionInfo":{"status":"ok","timestamp":1662266894122,"user_tz":-480,"elapsed":2,"user":{"displayName":"Nigel Leong","userId":"13146129826137816193"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["shutil.copy('/content/vit_probs.csv', '/content/drive/MyDrive')"],"metadata":{"id":"MgZ8Xlo5zgfI"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1c9sTY_2zqDodqHyJVX3rADf9LDxaJPxS","timestamp":1662218549383}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}